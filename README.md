# EEG entrainment study replication

TODO: fill in the project description section

## Replication Hardware

### Alexander's Hardware

1. EEG Headset: [OpenBCI Ultracortex "Mark IV" EEG Headset](https://shop.openbci.com/products/ultracortex-mark-iv) with [8-channel Cyton Board](https://shop.openbci.com/products/cyton-biosensing-board-8-channel) and [ThinkPulse Active Electrodes](https://shop.openbci.com/products/thinkpulse-active-electrode-8-channel-starter-kit). Current electrodes: Fp1, Fp2, Fz, C4, Pz, O1, Oz, O2
2. Monitor: LG UltraGear 24GQ50F 1920×1080 with AMD FreeSync (AMD's VSync) 48..165 Hz. Available fixed refresh rates: 165 Hz, 144 Hz, 120 Hz, 100 Hz, 60 Hz, 50 Hz. Potentially overclocks to 180 Hz — [here is the page that claims it, but maybe it's a different version, my box doesn't have the -B suffix](https://www.lg.com/uk/monitors/gaming/24gq50f-b/)

### Hardware with Andrew

1. **EEG Headsets**:

   - Biosemi ActiveTwo 32-channel clinical-grade EEG system with active electrodes
   - OpenBCI Ganglion board (?) with 4-6 passive AgCl electrodes
   - Various prototype mobile EEG systems

2. **Monitors**
   - Gigabye M28U 144 Hz Gsync / FreeSync. Works great on Windows at 144 Hz, and (I think) 120 Hz max on Mac.
   - 14" Macbook Pro with M3 Pro. Up to 120 Hz 'ProMotion'.
   - LG OLED TV with 144 Hz??

## Software components

### Working with recordings

1. `python -m scripts.replay_xdf <xdf_file>` creates an LSL stream that replays a recording by pushing data onto it every now and then (computed based on LSL chunk size and the frequency of the recording, 0.256s on OpenBCI recorded data and M1 macbook laptop). The recording is loaded via `load_xdf()` in `file_formats.py`, it does it via `pyxdf` and then converts the data to MNE format. TODO: check and document why it converts from uV to V by multiplying it 1e-6 (where does this difference in the formats is coming from?).

### Debugging a hardware connection

1. `python3 -m plot.EEG_rms2` finds and opens an EEG stream, displays uvRms (so you can check if electrodes are touching the skin properly), a spectrogram (aka PSD) and a chart with readings from each electrode. It's currently misnamed (it started with just with printing uvRms and grew into the current setup)

2. `python3 -m plot.EEG_rms2_pyglet_claude` the version of the previous script that was autogenerated with Claude. It plots everything in higher definition on macs because pygame doesn't support retina (TODO: actually check the reason for why it's higher definition).

### Computing IAF

1.  `python3 -m plot.alpha <xdf file>` computes IAF and plots various IAF-related plots from a recording via multiple methods. The first one is similar to what the authors of the original papers were doing: it gets a PSD, finds a peak and draws a red line through it. The second and third one slide a window and compute IAF in each of the ones and then plot a distribution of . The first method is fast, the second and the third one are slow (they can be commented out). The script supports multiple formats via `load_recording()` from `file_formats.py`.

2.  `python3 -m plot.EOEC <xdf file>` plots IAF from eye-open-eye-closed data. Subtracts the two (EO, EC) PSDs from each other and plots the resulting delta on the screen along with the found peak. Additionally plots the EO PSD (concated from all segments) as well as EC PSD (concated from all segments) allowing estimating the difference between these methods. TODO: check if concatenation are performed correctly, as they are currently done by concatenating raw data (which might produce some artifacts).

### Generating glass images

1. `python3 subject_stimulus_scripts/Glass_images/create_glass_images.py --radial --snr 0.5` to generate a radial image with the signal-to-noise ratio of 0.5. Replace `--radial` with `--concentric` for concetric images.

### Flicker code

`python3 flicker.py <flicker hz>`

The script currently have the same drawback: the physical size of the flash doesn't necessarily match the target physical size (7.9o × 7.9o (2.3 × 2.3 arc min2 per dot)). We'll implement calculating the physical flash size once the actual flash is stable.

You can use `SDL_VIDEO_WINDOW_POS` to move the window to the other monitor. For instance: `SDL_VIDEO_WINDOW_POS='1920,1'` (the first number is the width, the second is the 0-based monitor number). TODO: implement automatic picking

How it works. Utilizes VSync for the exact perfect flicker rate. Empirically it seems to work works fairly well. It attempts to find a target monitor refresh rate between 48 Hz and <target> Hz, then it draws X "off" frames and 1 "on" frame where X is computed based on the target refresh rate and the desired flicker frequency. A version of the previous code that uses `time.sleep()` to sleep for 75% of the inter-frame interval. Then busy-waits (spinlock-style) in a `while` loop. This produces a more stable FPS. Additionally prints more debug information on how long `flip()` takes plus target interval and the actual delay.

## Miscellaneous scripts

1. `python scripts/calculate_possible_flicker_rates.py 175 165 144 120 100`. Calculates possible flicker rates from a list of static fixed refresh rates as well as deltas between them so you can estimate max possible error between a person's IAF and their flicker rate
