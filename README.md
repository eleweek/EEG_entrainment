# EEG entrainment study replication

TODO: fill in the project description section

## Replication Hardware

### Alexander's Hardware

1. EEG Headset: [OpenBCI Ultracortex "Mark IV" EEG Headset](https://shop.openbci.com/products/ultracortex-mark-iv) with [8-channel Cyton Board](https://shop.openbci.com/products/cyton-biosensing-board-8-channel) and [ThinkPulse Active Electrodes](https://shop.openbci.com/products/thinkpulse-active-electrode-8-channel-starter-kit)
2. Monitor: LG UltraGear 24GQ50F 1920×1080 with AMD FreeSync (AMD's VSync) 48..165 Hz. Available fixed refresh rates: 165 Hz, 144 Hz, 120 Hz, 100 Hz, 60 Hz, 50 Hz. Potentially overclocks to 180 Hz — [here is the page that claims it, but maybe it's a different version, my box doesn't have the -B suffix](https://www.lg.com/uk/monitors/gaming/24gq50f-b/)

### Hardware with Andrew

1. **EEG Headsets**:

   - Biosemi ActiveTwo 32-channel clinical-grade EEG system with active electrodes
   - OpenBCI Ganglion board (?) with 4-6 passive AgCl electrodes
   - Various prototype mobile EEG systems

2. **Monitors**
   - Gigabye M28U 144 Hz Gsync / FreeSync. Works great on Windows at 144 Hz, and (I think) 120 Hz max on Mac.
   - 14" Macbook Pro with M3 Pro. Up to 120 Hz 'ProMotion'.
   - LG OLED TV with 144 Hz??

## Software components

### Working with recordings

1. `python -m scripts.replay_xdf <xdf_file>` creates an LSL stream that replays a recording by pushing data onto it every now and then (computed based on LSL chunk size and the frequency of the recording, 0.256s on OpenBCI recorded data and M1 macbook laptop). The recording is loaded via `load_xdf()` in `file_formats.py`, it does it via `pyxdf` and then converts the data to MNE format. TODO: check and document why it converts from uV to V by multiplying it 1e-6 (where does this difference in the formats is coming from?).

### Debugging a hardware connection

1. `python3 -m plot.EEG_rms2` finds and opens an EEG stream, displays uvRms (so you can check if electrodes are touching the skin properly), a spectrogram (aka PSD) and a chart with readings from each electrode. It's currently misnamed (it started with just with printing uvRms and grew into the current setup)

2. `python3 -m plot.EEG_rms2_pyglet_claude` the version of the previous script that was autogenerated with Claude. It plots everything in higher definition on macs because pygame doesn't support retina (TODO: actually check the reason for why it's higher definition).

### Computing IAF

1.  `python3 -m plot.alpha <xdf file>` computes IAF and plots various IAF-related plots from a recording via multiple methods. The first one is similar to what the authors of the original papers were doing: it gets a PSD, finds a peak and draws a red line through it. The second and third one slide a window and compute IAF in each of the ones and then plot a distribution of . The first method is fast, the second and the third one are slow (they can be commented out). The script supports multiple formats via `load_recording()` from `file_formats.py`.

2.  `python3 -m plot.EOEC <xdf file>` plots IAF from eye-open-eye-closed data. Subtracts the two (EO, EC) PSDs from each other and plots the resulting delta on the screen along with the found peak. Additionally plots the EO PSD (concated from all segments) as well as EC PSD (concated from all segments) allowing estimating the difference between these methods. TODO: check if concatenation are performed correctly, as they are currently done by concatenating raw data (which might produce some artifacts).

### Generating glass images

1. `python3 subject_stimulus_scripts/Glass_images/create_glass_images.py --radial --snr 0.5` to generate a radial image with the signal-to-noise ratio of 0.5. Replace `--radial` with `--concentric` for concetric images.

### Flicker code

Currently the repository contains multiple versions of flicker code, each with its own pros and cons. It's unfortunately tricky to generate flicker with a stable rate, so we experimented with different ways of doing it.

All of the scripts currently have the same drawback: the physical size of the flash doesn't necessarily match the target physical size (7.9o × 7.9o (2.3 × 2.3 arc min2 per dot)). We'll implement calculating the physical flash size once the actual flash is stable.

Note that the scripts aren't standardised. In particular, some scripts take monitor hz as their arguments, but most take the target refresh rate. Each of the scripts is an experiment, and we'll likely end up with only one working version.

For all pygame-based scripts you can use `SDL_VIDEO_WINDOW_POS` to move the window to the other monitor. For instance: `SDL_VIDEO_WINDOW_POS='1920,1'` (the first number is the width, the second is the 0-based monitor number). TODO: implement automatic picking

1. `python3 flash_light_simple2_better_loop.py <flicker hz>`. Pygame-based code that attempts to utilize VSync for the exact perfect flicker rate. Currently it's unclear how well it works (just a guess: it doesn't). It attempts to find a target monitor refresh rate between 48 Hz and 165 Hz, then it draws X "off" frames and 1 "on" frame where X is computed based on the target refresh rate and the desired flicker frequency. A version of the previous code that uses `time.sleep()` to sleep for 75% of the inter-frame interval. Then busy-waits (spinlock-style) in a `while` loop. This produces a more stable FPS. Additionally prints more debug information on how long `flip()` takes plus target interval and the actual delay.
2. `python3 flash_light_metal3.py`. Uses Apple Metal API for GPU-accelerated low-level rendering. It currently hardcodes the flicker rate to be 10Hz and the monitor refresh rate to be 60 Hz. Single-frame flashing (as the study requires). For performance-monitoring, aggregates FPS over 60 and 300 frames to allow estimating how stable the flicker is. THE PROBLEM: The script is currently fullscreen but the §window doesn't center the flicker and just creates a big white background around it while putting the flicker part in the corner.
3. `python3 flash_light_metal4.py`. Another script that uses Metal. Also AI-generated, simplified architecture. It also uses simplified flashing: 50% on, 50% off (wouldn't work for the study but potentially useful for debugging)

## Display testing scripts

1. `python scripts/fps_test.py`. Tests if a monitor can actually achieve a target refresh rate (hardcoded as 117 Hz) on a monitor. It does call `flip()` but it doesn't do any flicker. Prints expected FPS and actual FPS (computed via `clock.get_fps()`). It's unclear if this script is particularly useful.

2. `python scripts/vsync_test.py`. Full-screen Vsync-toggle test both `pygame_gui` and `pygame`. Press Enter to toggle on/off Vsync to see how it'd affect the FPS that's displayed in the center of the screen.

3. `python scripts/vsync_test2.py`. Full-screen Vsync-toggle test that only uses `pygame`, an updated version of the previous script.

## Miscellaneous scripts

1. `python scripts/calculate_possible_flicker_rates.py 175 165 144 120 100`. Calculates possible flicker rates from a list of static fixed refresh rates as well as deltas between them so you can estimate max possible error between a person's IAF and their flicker rate
